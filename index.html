<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Batchaya Yacynte – Autonomous Systems Engineer</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
    body { font-family: Arial, sans-serif; margin: 0; background: #ffffff; color: #111; }
    .container { width: 90%; max-width: 900px; margin: auto; padding: 40px 0; }
    h1, h2 { font-weight: 600; }
    h1 { font-size: 32px; margin-bottom: 5px; }
    .subtitle { font-size: 18px; color: #555; margin-bottom: 20px; }
    .links a { margin-right: 15px; text-decoration: none; color: #0066cc; }
    .section { margin-top: 50px; }
    .project { margin-bottom: 40px; }
    .project img { max-width: 100%; border: 1px solid #ddd; margin-top: 10px; }
    footer { margin-top: 50px; font-size: 14px; color: #666; text-align: center; }
</style>
</head>

<body>
<div class="container">

    <!-- HEADER -->
    <h1>Batchaya Yacynte</h1>
    <div class="subtitle">Autonomous Systems Engineer | UAV Navigation | Visual Perception</div>
    <div class="links">
        <a href="mailto:batchaya.yacynte@gmail.com">Email</a>
        <a href="https://www.linkedin.com/in/batchaya-yacynte-256357227/">LinkedIn</a>
        <a href="https://github.com/Yacynte">GitHub</a>
        <a href="https://ieeexplore.ieee.org/document/10735689">Publication</a>
    </div>

    <!-- ABOUT SECTION -->
    <div class="section">
        <h2>About Me</h2>
        <p>
            Engineer focused on real-time perception for drones and mobile robots.
            Experience with visual odometry, sensor fusion, event-based cameras,
            and virtual testing environments for autonomous navigation.
        </p>
    </div>

    <!-- PROJECTS -->
    <div class="section">
        <h2>Projects</h2>

        <div class="project">
            <h3>Neuromorphic Event-Camera Optical Flow – Triplet Matcher (Fraunhofer IVI)</h3>
            <p>
            Neuromorphic event cameras capture pixel-level brightness changes asynchronously at microsecond resolution. They enable perception during extreme motion and low-light conditions where conventional frame cameras fail.
            
            At Fraunhofer IVI, I developed a fast triplet-matching optical flow pipeline for an IDS event-based camera, focused on high-speed motion estimation for autonomous systems.
            </p>
            <h4>My contributions</h4>
            <ul>
              <li>Designed the full Python processing pipeline for event-stream optical flow</li>
              <li>Implemented temporal buffering and timestamp synchronization to maintain precise event ordering</li>
              <li>Generated time-surface representations for spatial-temporal context aggregation</li>
                <li> Built temporal triplet matching to extract stable motion correspondences from sparse asynchronous events </li>
                <li> Added confidence filtering and outlier rejection to improve robustness in dynamic scenes </li>
            </ul>

            <h4> Performance </h4>
            <ul>
                <li> Achieved <3 ms latency on representative sequences (no GPU), suitable for reactive navigation studies </li>
                <li> Demonstrated strong robustness to motion blur and challenging lighting where frame-based methods degrade </li>
            </ul>
            <p>
                The next development stage will target object specific time to collision, real-time deployment in C++ with GPU acceleration and ROS2 integration into robotic navigation stacks.
            </p> 
            <img src="IMAGE_PLACEHOLDER_HERE" alt="Unreal Environment Demo">
        </div>

        <div class="project">
            <h3>Drone Repositioning & Virtual Testing</h3>
            <p>
                Unreal Engine environment for UAV navigation validation with dynamic weather.
                Built RTSP camera streaming using MediaMTX + FFmpeg and TCP control link to navigation system.
                <br><strong>Tech:</strong> Python, UE5 (Blueprints/C++), FFmpeg, ROS2
            </p>
            <img src="IMAGE_PLACEHOLDER_HERE" alt="Unreal Environment Demo">
        </div>

        <div class="project">
            <h3>Stereo Visual Odometry for UAVs</h3>
            <p>
                Monocular/Stereo VO, &lt;1% translation error on KITTI.
                Presented at IEEE REM 2024.
                <br><strong>Tech:</strong> Python, OpenCV, Optimization
                <br><a href="https://ieeexplore.ieee.org/document/10735689">Paper Link</a>
            </p>
            <img src="IMAGE_PLACEHOLDER_HERE" alt="VO Trajectory Example">
        </div>

    </div>

    <!-- CONTACT -->
    <div class="section">
        <h2>Contact</h2>
        <p>batchaya.yacynte@gmail.com • Ingolstadt, Germany</p>
    </div>

</div>

<footer>
    © 2025 Batchaya Yacynte
</footer>
</body>
</html>
